{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f8c78b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, time\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "import bson\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54ef67",
   "metadata": {},
   "source": [
    "* A partir du fichier trips_.json, remplacez les espaces des clés par un underscore, puis mettez en base en changeant les chaîne de caractères qui concerne des grandeurs numériques par le type integer ou float et les champs de date ($date) doit être sous format datetime.datetime. Ainsi les champs préfixé '$number...' suivent  l'exemple ci-dessous(cherchez du côté de la librairie bson, il existe une fonction utilitaire, il faut aussi réduire la profondeur):\n",
    "* From the file trips_.json, replace the spaces in the keys with underscores. Then insert the data into the database while converting string values that represent numerical quantities into either integer or float types. Fields containing dates ($date) must be converted to the datetime.datetime format. Also, fields prefixed with $number... should follow the example below (look into the bson library — there is a utility function for this). The depth of the document should also be reduced.\n",
    "\n",
    "```json\n",
    "{'tripduration': {'$numberInt': 379}}\n",
    "```\n",
    "\n",
    "en :\n",
    "\n",
    "```json\n",
    "{'tripduration': 379}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "750ebabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_document(doc):\n",
    "    if isinstance(doc, dict):\n",
    "        # Handle special MongoDB extended JSON values\n",
    "        if \"$numberInt\" in doc:\n",
    "            return int(doc[\"$numberInt\"]) #If the document is like: {\"$numberInt\": \"42\"}, this will return 42 as a Python int.\n",
    "        elif \"$numberDouble\" in doc:\n",
    "            return float(doc[\"$numberDouble\"])\n",
    "        elif \"$numberLong\" in doc:\n",
    "            return int(doc[\"$numberLong\"])\n",
    "        elif \"$date\" in doc:\n",
    "            date_val = doc[\"$date\"]\n",
    "            if isinstance(date_val, dict) and \"$numberLong\" in date_val:\n",
    "                return datetime.fromtimestamp(int(date_val[\"$numberLong\"]) / 1000.0) #Dates are stored in JSON as a Unix timestamp in milliseconds Python's datetime.fromtimestamp() expects seconds, so we divide by 1000.\n",
    "            elif isinstance(date_val, str): #If the date is an ISO-formatted string\n",
    "                return datetime.fromisoformat(date_val.replace(\"Z\", \"+00:00\")) #.replace(\"Z\", \"+00:00\") makes it compatible with datetime.fromisoformat\n",
    "                                                                                #Converts the string to a native datetime object\n",
    "\n",
    "        # Clean key names and recursively clean values\n",
    "        cleaned = {}\n",
    "        for key, value in doc.items():\n",
    "            clean_key = key.replace(\" \", \"_\")\n",
    "            cleaned[clean_key] = clean_document(value) #handling normal dictionaries (not just special MongoDB fields)\n",
    "        return cleaned\n",
    "\n",
    "    elif isinstance(doc, list): #f doc is a list\n",
    "        return [clean_document(item) for item in doc] #this goes through each item in the list and applies clean_document() recursively.\n",
    "    \n",
    "    else:\n",
    "        return doc #If the input doc is: a string (\"hello\"), an integer (123), a float (3.14), None, or anything that isn’t a dict or list…, \n",
    "                   #Then it just returns it as-is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "949b8263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tripduration': 307, 'start_station_id': 3118, 'start_station_name': 'McGuinness Blvd & Eagle St', 'end_station_id': 3119, 'end_station_name': 'Vernon Blvd & 50 Ave', 'bikeid': 23477, 'usertype': 'Subscriber', 'birth_year': 1987, 'gender': 1, 'start_station_location': {'type': 'Point', 'coordinates': [-73.95284, 40.73555]}, 'end_station_location': {'type': 'Point', 'coordinates': [-73.95411749, 40.74232744]}, 'start_time': datetime.datetime(2016, 1, 1, 8, 4, 31), 'stop_time': datetime.datetime(2016, 1, 1, 8, 9, 38)}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "cleaned_documents = [] #Creates an empty list that will store all the cleaned documents.\n",
    "\n",
    "with open(\"trips_.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip() #removes leading/trailing whitespace and newline characters\n",
    "        if not line:\n",
    "            continue\n",
    "        raw_doc = json.loads(line) #converts the JSON string into a Python dictionary \n",
    "        cleaned = clean_document(raw_doc) #applies the cleaning function I defined earlier\n",
    "        cleaned_documents.append(cleaned) #Adds the cleaned version of the document to the cleaned_documents list\n",
    "\n",
    "# Show one example\n",
    "print(cleaned_documents[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ea8ec",
   "metadata": {},
   "source": [
    "Après avoir mis en base et uniquement, assurez-vous qu'il n'y a pas de doublons, si il y en a, écrivez une fonction python permettant de les retirer (sans à avoir à faire de téléchargement) 'delete dublicates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1008a976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared existing documents.\n",
      "Inserted 10019 documents.\n"
     ]
    }
   ],
   "source": [
    "# Connect to local MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"bikedata\"]\n",
    "collection = db[\"trips\"]\n",
    "\n",
    "\n",
    "# Clear existing documents to avoid duplicate stacking\n",
    "collection.delete_many({})\n",
    "print(\"Cleared existing documents.\")\n",
    "\n",
    "# Insert cleaned documents\n",
    "collection.insert_many(cleaned_documents)\n",
    "print(f\"Inserted {len(cleaned_documents)} documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d0d3647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 19 duplicates.\n"
     ]
    }
   ],
   "source": [
    "from bson.json_util import dumps #converts a Python dict (or MongoDB document) into a JSON-formatted string, \n",
    "                                #including support for special MongoDB types like ObjectId, datetime, etc.\n",
    "\n",
    "def remove_duplicates(collection):\n",
    "    seen = set()\n",
    "    duplicates = []\n",
    "\n",
    "    for doc in collection.find(): #Loop Through Every Document in the Collection\n",
    "        doc_copy = doc.copy() #Prepare the Document for Comparison\n",
    "        doc_copy.pop(\"_id\", None) #Even if two documents are otherwise identical, their _ids will differ, so we remove _id before comparison.\n",
    "        doc_str = dumps(doc_copy, sort_keys=True) #Converts the document into a string using bson.json_util.dumps()\n",
    "                                                #sort_keys=True ensures a consistent order for fields \n",
    "\n",
    "        if doc_str in seen: #If this stringified document has been seen before → it’s a duplicate → store its _id in duplicates\n",
    "            duplicates.append(doc[\"_id\"])\n",
    "        else:\n",
    "            seen.add(doc_str) #If not → add it to seen\n",
    "\n",
    "    if duplicates:\n",
    "        collection.delete_many({\"_id\": {\"$in\": duplicates}}) #Uses $in to match any document with one of those _ids\n",
    "        print(f\"Removed {len(duplicates)} duplicates.\")\n",
    "    else:\n",
    "        print(\"No duplicates found.\")\n",
    "\n",
    "remove_duplicates(collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a6b9e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_trips.json to:\n",
      "/Users/pernebayarailym/Documents/Portfolio_Projects_AP/Simplon_DE_Projects/Python_Projects/MongoDB_practice/cleaned_trips.json\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(os.getcwd(), \"cleaned_trips.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc in cleaned_documents:\n",
    "        json.dump(doc, f, default=str)  # default=str for datetime\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"Saved cleaned_trips.json to:\")\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95997b49",
   "metadata": {},
   "source": [
    "De plus, des hypothèses d'incohérences ont été émises par les parties prenantes, il s'agit d'écrire pour chacune de ces hypothèses une fonction python qui va détecter les documents incriminés et les flagger avec un champs supplémentaire pour rectification/enquête ultérieure :\n",
    "\n",
    "* Un vélo loué deux fois, mais la deuxième période de location démarre avant le rendu de la première période de location, ce qui n'est pas normal, ou tout autre chevanchement de période.\n",
    "* Un utilisateur trop jeune (le service est réservé au + de 13 ans)\n",
    "* La date de naissance n'est pas renseignée\n",
    "* Des locations trop courtes (1 secondes)\n",
    "* Des temps de location incohérents par rapport au start_time et au end_time\n",
    "\n",
    "\n",
    "Faites un rapport détaillé des anomalies trouvées (nombres d'occurences)\n",
    "\n",
    "* In addition, stakeholders have raised hypotheses about potential data inconsistencies. You are required to write a Python function for each of these hypotheses to detect the problematic documents and flag them with an additional field for future correction/investigation:\n",
    "\n",
    "- A bike is rented twice, but the second rental period starts before the first one has ended, which is abnormal, or any other overlapping rental periods.\n",
    "- A user who is too young (the service is restricted to those over 13 years old).\n",
    "- The birth date is missing.\n",
    "- Very short rentals (e.g., 1 second long).\n",
    "- Inconsistent rental durations compared to the recorded start_time and end_time.\n",
    "\n",
    "Create a detailed report of the anomalies found (number of occurrences)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda3e6c3",
   "metadata": {},
   "source": [
    "## 1. Overlapping Bike Rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c87d7249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overlapping_rental': 2}\n"
     ]
    }
   ],
   "source": [
    "def detect_overlapping_bike_rentals(collection): #I developed a Python function to detect overlapping bike rentals in the MongoDB dataset.\n",
    "    from collections import defaultdict #to import defaultdict to automatically create lists for new keys \n",
    "\n",
    "    bike_trips = defaultdict(list) #dictionary to group trips by bike ID, e.g., {23477: [trip1, trip2, ...]}\n",
    "    overlap_count=0 #to count the number of overlapping trips\n",
    "\n",
    "    #group trips by bike_id\n",
    "    for trip in collection.find({\"start_time\":{\"$exists\": True}, \"stop_time\": {\"$exists\": True}}): #sorted each group by start_time to analyze them chronologically.\n",
    "        bike_trips[trip[\"bikeid\"]].append(trip)\n",
    "\n",
    "    #check overlap per bike\n",
    "    for trips in bike_trips.values():\n",
    "        sorted_trips =sorted(trips, key=lambda x: x[\"start_time\"]) #Then, for each bike, I checked if a new trip started before the previous one ended which would indicate a scheduling conflict or data error.\n",
    "\n",
    "        for earlier, later in zip(sorted_trips, sorted_trips[1:]):\n",
    "            if later[\"start_time\"] < earlier[\"stop_time\"]:\n",
    "                collection.update_one({\"_id\": later[\"_id\"]}, {\"$set\": {\"anomaly\": \"overlapping_rental\"}}) #If an overlap was found, I flagged the trip by adding an \"anomaly\": \"overlapping_rental\" field in the database. \n",
    "                overlap_count += 1\n",
    "\n",
    "    return {\"overlapping_rental\": overlap_count}\n",
    "\n",
    "result = detect_overlapping_bike_rentals(collection)\n",
    "print(result) #Finally, I returned the total number of overlaps detected for reporting purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83159bd",
   "metadata": {},
   "source": [
    "## 2. Users under 13 Years Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c48f08af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'underage_user': 2}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime # we import datetime to get the current year (to calculate user's ages)\n",
    "\n",
    "def detect_underage_users(collection): # define a function that takes a MongoDB collection as input\n",
    "    current_year = datetime.now().year # Get the current year (eg 2025) so we can calculate the user;s age\n",
    "\n",
    "#count how many users have a birth year that means they are younger than 13\n",
    "    underage_count = collection.count_documents({\n",
    "        \"birth_year\": { \"$exists\": True, #make sure birth_year field exists\n",
    "                       \"$ne\": \"\", #And it's not an empty string\n",
    "                       \"$gt\": current_year - 13} #and birth year is greater than (current year - 13) = too young\n",
    "    })\n",
    "\n",
    "    # tag those name underage users with an \"anomaly\" field in the database\n",
    "    collection.update_many(\n",
    "        {\"birth_year\": {\"$exists\": True, \"$ne\": \"\", \"$gt\":current_year-13}}, #same filter as above to update\n",
    "        {\"$set\": {\"anomaly\": \"underage_user\"}} #add or update the anomaly field in their document\n",
    "    )\n",
    "\n",
    "    return {\"underage_user\": underage_count} #return a report with the number of underage users detected\n",
    "\n",
    "result = detect_underage_users(collection) #call the function and store the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb899dc",
   "metadata": {},
   "source": [
    "## 3. Detect missing Birth Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c1f447ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missing_birth_year': 1989}\n"
     ]
    }
   ],
   "source": [
    "def detect_missing_birth_year(collection): #define the function that takes monodb collection as input\n",
    "\n",
    "    #count how many docs have a missing birth year either empty string or None\n",
    "    missing_count = collection.count_documents({\n",
    "        \"birth_year\": {\"$in\": [\"\", None]} \n",
    "    })\n",
    "\n",
    "    # for those documents, update them by adding a new field: \"anomaly\": \"missing_birth_year\"\n",
    "    collection.update_many(\n",
    "        {\"birth_year\":  {\"$in\": [\"\", None]}}, \n",
    "        {\"$set\": {\"anomaly\": \"missing_birth_year\"}} #add the anomaly tag to those documents\n",
    "    )\n",
    "\n",
    "    return {\"missing_birth_year\": missing_count} #return a report with the number of documents with missing birth year\n",
    "\n",
    "result = detect_missing_birth_year(collection) #call the function and store the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd568e9",
   "metadata": {},
   "source": [
    "## 4. Detect Very Short Rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0e59bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'very_short_rentals': 4}\n"
     ]
    }
   ],
   "source": [
    "def detect_short_rentals(collection):\n",
    "    short_count =collection.count_documents({\"tripduration\": {\"$lte\": 1}}) #count how many trips have a duration of 1 second or less\n",
    "    collection.update_many(\n",
    "        {\"tripduration\":{\"$lte\": 1}},\n",
    "        {\"$set\": {\"anomaly\": \"very_short_rentals\"}}\n",
    "    )\n",
    "    return {\"very_short_rentals\": short_count} #return a report with the number of very short rentals detected\n",
    "\n",
    "result = detect_short_rentals(collection)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f924d",
   "metadata": {},
   "source": [
    "## 5. Detect Inconsistent Rental Durations compared to the recorded start_time and end_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "42461d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'duration_mismatch': 10}\n"
     ]
    }
   ],
   "source": [
    "def detect_duration_mismatches(collection): #define fucntion to find inccorrect durations\n",
    "    mismatch_count = 0 #initialize a counter for mismatched duration cases\n",
    "\n",
    "    #loop through all trips that have start_time , stop_time, and tripduration fields\n",
    "    for trip in collection.find({\"start_time\": {\"$exists\": True}, \"stop_time\": {\"$exists\": True}, \"tripduration\": {\"$exists\":True}}):\n",
    "        #calculate actual duration in seconds between start and stop times\n",
    "        actual_duration = int((trip[\"stop_time\"] - trip[\"start_time\"]).total_seconds()) #total_seconds() gives the duration in seconds\n",
    "\n",
    "        #check if the actual duration differs from the recorded one by more than 10 sec \n",
    "        if abs(actual_duration-trip[\"tripduration\"])>10: #allow a small 10 sec difference margin\n",
    "            collection.update_one(\n",
    "                {\"_id\": trip[\"_id\"]}, #find the doc by its unique mongodb id\n",
    "                {\"$set\": {\"anomaly\": \"duration_mismatch\"}} #add the anomaly tag to that document\n",
    "            )\n",
    "            mismatch_count += 1 #increase mismatch counter\n",
    "\n",
    "    return {\"duration_mismatch\": mismatch_count} #return a report with the number of mismatched durations detected\n",
    "\n",
    "result = detect_duration_mismatches(collection)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bc6bde63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overlapping_rental': 2, 'underage_user': 2, 'missing_birth_year': 1989, 'very_short_rentals': 4, 'duration_mismatch': 10}\n"
     ]
    }
   ],
   "source": [
    "def run_all_anomaly_checks(collection):\n",
    "    report = {}\n",
    "    report.update(detect_overlapping_bike_rentals(collection))\n",
    "    report.update(detect_underage_users(collection))\n",
    "    report.update(detect_missing_birth_year(collection))\n",
    "    report.update(detect_short_rentals(collection))\n",
    "    report.update(detect_duration_mismatches(collection))\n",
    "    return report\n",
    "\n",
    "result = run_all_anomaly_checks(collection)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ab216",
   "metadata": {},
   "source": [
    "Puis, après avoir fait un nettoyage et écarté les locations suspectes, répondez aux questions métier qui suivent :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ee46c",
   "metadata": {},
   "source": [
    "* Changez le gender 0 en gender 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "efe6281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modified_count': 2009}\n"
     ]
    }
   ],
   "source": [
    "def update_gender_zero_to_one(collection):\n",
    "    result = collection.update_many(\n",
    "        {\"gender\": 0}, # Filter: find all documents where gender is 0\n",
    "        {\"$set\": {\"gender\": 1}}  # Update: set gender to 1\n",
    "    )\n",
    "\n",
    "    return {\"modified_count\": result.modified_count} # Return number of updated documents\n",
    "\n",
    "result = update_gender_zero_to_one(collection)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6353f0",
   "metadata": {},
   "source": [
    "* Quels sont les 5 trajets (start station → end station) les plus fréquents pour les utilisateurs de genre féminin ? (gender = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033a534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. From: Central Park S & 6 Ave → To: Central Park S & 6 Ave | Count: 30\n",
      "2. From: 5 Ave & E 78 St → To: Central Park West & W 85 St | Count: 12\n",
      "3. From: Central Park West & W 85 St → To: Central Park West & W 85 St | Count: 11\n",
      "4. From: Central Park West & W 76 St → To: Central Park West & W 76 St | Count: 10\n",
      "5. From: Central Park West & W 85 St → To: Central Park S & 6 Ave | Count: 9\n"
     ]
    }
   ],
   "source": [
    "def top_5_female_trips(collection):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"gender\": 1}},  # Only include female users\n",
    "        {\"$group\": {\n",
    "            \"_id\": {\n",
    "                \"from\": \"$start_station_name\",\n",
    "                \"to\": \"$end_station_name\"\n",
    "            },\n",
    "            \"count\": {\"$sum\": 1}  # Count how many times each (start → end) pair occurs\n",
    "        }},\n",
    "        {\"$sort\": {\"count\": -1}},  # Sort by count in descending order\n",
    "        {\"$limit\": 5}  # Only return the top 5 most frequent trips\n",
    "    ]\n",
    "\n",
    "    result = list(collection.aggregate(pipeline))  # Run the aggregation pipeline\n",
    "    return result\n",
    "\n",
    "top_trips = top_5_female_trips(collection)\n",
    "\n",
    "for i, trip in enumerate(top_trips, 1):\n",
    "    print(f\"{i}. From: {trip['_id']['from']} → To: {trip['_id']['to']} | Count: {trip['count']}\")\n",
    "\n",
    "    #Filter: gender = 1 (female users)\n",
    "#Group by: start_station_name + end_station_name\n",
    "#Count how many times each trip occurs\n",
    "#Sort by count descending\n",
    "#Limit: top\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d8fb7",
   "metadata": {},
   "source": [
    "* Quel est le nombre total de trajets par type d’utilisateur (Subscriber vs Customer) pour le premier jour de l'année ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bc899bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usertype: Customer → Total Trips: 1360\n",
      "Usertype: Subscriber → Total Trips: 4879\n"
     ]
    }
   ],
   "source": [
    "#Filter trips by date: start_time should fall on January 1st (of any year, or a specific year depending on your dataset).\n",
    "#Group by: usertype\n",
    "#Count: total trips per type\n",
    "\n",
    "def trips_by_usertype_on_jan1_any_year(collection):\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"$expr\": {\n",
    "                    \"$and\": [\n",
    "                        {\"$eq\": [{\"$dayOfMonth\": \"$start_time\"}, 1]},\n",
    "                        {\"$eq\": [{\"$month\": \"$start_time\"}, 1]}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$group\": {\n",
    "                \"_id\": \"$usertype\",\n",
    "                \"total_trips\": {\"$sum\": 1}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return list(collection.aggregate(pipeline))\n",
    "\n",
    "results = trips_by_usertype_on_jan1_any_year(collection)\n",
    "\n",
    "for item in results:\n",
    "    print(f\"Usertype: {item['_id']} → Total Trips: {item['total_trips']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937e2c9",
   "metadata": {},
   "source": [
    "* Quelle est la durée moyenne des trajets par station de départ pour les trajets commençant entre 7h et 9h ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ee1e5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station: E 2 St & 2 Ave → Avg Duration: 5138.67 sec\n",
      "Station: Riverside Blvd & W 67 St → Avg Duration: 4630.0 sec\n",
      "Station: Broadway & W 29 St → Avg Duration: 3845.0 sec\n",
      "Station: Spruce St & Nassau St → Avg Duration: 3102.0 sec\n",
      "Station: Broadway & W 51 St → Avg Duration: 3023.0 sec\n",
      "Station: 5 Ave & E 73 St → Avg Duration: 2334.0 sec\n",
      "Station: W 46 St & 11 Ave → Avg Duration: 1760.0 sec\n",
      "Station: Queens Plaza North & Crescent St → Avg Duration: 1638.0 sec\n",
      "Station: FDR Drive & E 35 St → Avg Duration: 1620.0 sec\n",
      "Station: Fulton St & Broadway → Avg Duration: 1555.0 sec\n",
      "Station: Vesey Pl & River Terrace → Avg Duration: 1426.0 sec\n",
      "Station: W 70 St & Amsterdam Ave → Avg Duration: 1384.0 sec\n",
      "Station: Carlton Ave & Park Ave → Avg Duration: 1378.5 sec\n",
      "Station: Central Park S & 6 Ave → Avg Duration: 1327.0 sec\n",
      "Station: N 12 St & Bedford Ave → Avg Duration: 1315.0 sec\n",
      "Station: Greenwich Ave & 8 Ave → Avg Duration: 1301.67 sec\n",
      "Station: 11 Ave & W 27 St → Avg Duration: 1275.0 sec\n",
      "Station: Franklin St & Dupont St → Avg Duration: 1241.0 sec\n",
      "Station: Dean St & 4 Ave → Avg Duration: 1194.5 sec\n",
      "Station: Marcus Garvey Blvd & Macon St → Avg Duration: 1191.0 sec\n",
      "Station: E 41 St & Madison Ave → Avg Duration: 1179.0 sec\n",
      "Station: E 27 St & 1 Ave → Avg Duration: 1166.0 sec\n",
      "Station: W 26 St & 10 Ave → Avg Duration: 1157.0 sec\n",
      "Station: Clermont Ave & Park Ave → Avg Duration: 1146.0 sec\n",
      "Station: Mott St & Prince St → Avg Duration: 1132.0 sec\n",
      "Station: 6 Ave & W 33 St → Avg Duration: 1128.0 sec\n",
      "Station: Metropolitan Ave & Meeker Ave → Avg Duration: 1116.0 sec\n",
      "Station: Lexington Ave & E 24 St → Avg Duration: 1073.0 sec\n",
      "Station: DeKalb Ave & Hudson Ave → Avg Duration: 1070.0 sec\n",
      "Station: E 47 St & 1 Ave → Avg Duration: 1066.0 sec\n",
      "Station: 45 Rd & 11 St → Avg Duration: 1029.5 sec\n",
      "Station: Little West St & 1 Pl → Avg Duration: 1023.5 sec\n",
      "Station: Centre St & Chambers St → Avg Duration: 984.0 sec\n",
      "Station: 1 Ave & E 78 St → Avg Duration: 968.0 sec\n",
      "Station: E 25 St & 2 Ave → Avg Duration: 966.5 sec\n",
      "Station: W 52 St & 9 Ave → Avg Duration: 903.0 sec\n",
      "Station: W 20 St & 7 Ave → Avg Duration: 899.0 sec\n",
      "Station: 9 Ave & W 18 St → Avg Duration: 887.0 sec\n",
      "Station: N 8 St & Driggs Ave → Avg Duration: 884.0 sec\n",
      "Station: E 17 St & Broadway → Avg Duration: 877.33 sec\n",
      "Station: MacDougal St & Washington Sq → Avg Duration: 877.0 sec\n",
      "Station: E 33 St & 2 Ave → Avg Duration: 861.0 sec\n",
      "Station: W 43 St & 6 Ave → Avg Duration: 852.0 sec\n",
      "Station: Columbia St & Rivington St → Avg Duration: 847.25 sec\n",
      "Station: E 85 St & York Ave → Avg Duration: 847.0 sec\n",
      "Station: Suffolk St & Stanton St → Avg Duration: 816.0 sec\n",
      "Station: Leonard St & Boerum St → Avg Duration: 781.0 sec\n",
      "Station: W 31 St & 7 Ave → Avg Duration: 779.33 sec\n",
      "Station: W 43 St & 10 Ave → Avg Duration: 779.0 sec\n",
      "Station: Avenue D & E 12 St → Avg Duration: 766.0 sec\n",
      "Station: E 71 St & 2 Ave → Avg Duration: 763.0 sec\n",
      "Station: E 2 St & Avenue B → Avg Duration: 758.5 sec\n",
      "Station: E 20 St & FDR Drive → Avg Duration: 752.0 sec\n",
      "Station: W 41 St & 8 Ave → Avg Duration: 750.0 sec\n",
      "Station: W 47 St & 10 Ave → Avg Duration: 712.0 sec\n",
      "Station: Columbus Ave & W 72 St → Avg Duration: 702.0 sec\n",
      "Station: Washington Ave & Park Ave → Avg Duration: 657.0 sec\n",
      "Station: Clinton Ave & Flushing Ave → Avg Duration: 639.0 sec\n",
      "Station: W 26 St & 8 Ave → Avg Duration: 629.0 sec\n",
      "Station: W 42 St & 8 Ave → Avg Duration: 626.75 sec\n",
      "Station: E 84 St & 1 Ave → Avg Duration: 621.5 sec\n",
      "Station: E 47 St & 2 Ave → Avg Duration: 613.0 sec\n",
      "Station: 1 Ave & E 15 St → Avg Duration: 589.0 sec\n",
      "Station: W 38 St & 8 Ave → Avg Duration: 586.67 sec\n",
      "Station: Grand Army Plaza & Central Park S → Avg Duration: 582.33 sec\n",
      "Station: Avenue D & E 3 St → Avg Duration: 581.2 sec\n",
      "Station: Sullivan St & Washington Sq → Avg Duration: 572.0 sec\n",
      "Station: W 22 St & 8 Ave → Avg Duration: 568.0 sec\n",
      "Station: E 39 St & 2 Ave → Avg Duration: 563.0 sec\n",
      "Station: Madison St & Clinton St → Avg Duration: 560.14 sec\n",
      "Station: Watts St & Greenwich St → Avg Duration: 558.0 sec\n",
      "Station: Greenwich St & W Houston St → Avg Duration: 551.0 sec\n",
      "Station: E 2 St & Avenue C → Avg Duration: 549.0 sec\n",
      "Station: E 59 St & Madison Ave → Avg Duration: 541.0 sec\n",
      "Station: Rivington St & Chrystie St → Avg Duration: 539.5 sec\n",
      "Station: Barrow St & Hudson St → Avg Duration: 535.0 sec\n",
      "Station: Nostrand Ave & Myrtle Ave → Avg Duration: 520.0 sec\n",
      "Station: W 13 St & 6 Ave → Avg Duration: 519.0 sec\n",
      "Station: E 11 St & 2 Ave → Avg Duration: 499.0 sec\n",
      "Station: E 77 St & 3 Ave → Avg Duration: 496.0 sec\n",
      "Station: Broadway & W 60 St → Avg Duration: 491.0 sec\n",
      "Station: E 10 St & Avenue A → Avg Duration: 483.0 sec\n",
      "Station: W 39 St & 9 Ave → Avg Duration: 476.33 sec\n",
      "Station: Norfolk St & Broome St → Avg Duration: 471.5 sec\n",
      "Station: Hudson St & Reade St → Avg Duration: 469.0 sec\n",
      "Station: Pershing Square North → Avg Duration: 458.2 sec\n",
      "Station: 2 Ave & E 31 St → Avg Duration: 457.0 sec\n",
      "Station: E 15 St & 3 Ave → Avg Duration: 449.5 sec\n",
      "Station: Willoughby Ave & Hall St → Avg Duration: 445.0 sec\n",
      "Station: 8 Ave & W 33 St → Avg Duration: 436.25 sec\n",
      "Station: W 33 St & 7 Ave → Avg Duration: 434.62 sec\n",
      "Station: Christopher St & Greenwich St → Avg Duration: 424.0 sec\n",
      "Station: St Marks Pl & 1 Ave → Avg Duration: 423.0 sec\n",
      "Station: E 20 St & 2 Ave → Avg Duration: 422.75 sec\n",
      "Station: South End Ave & Liberty St → Avg Duration: 417.0 sec\n",
      "Station: W 74 St & Columbus Ave → Avg Duration: 410.0 sec\n",
      "Station: Broadway & E 22 St → Avg Duration: 403.0 sec\n",
      "Station: E 31 St & 3 Ave → Avg Duration: 399.0 sec\n",
      "Station: W 52 St & 5 Ave → Avg Duration: 392.0 sec\n",
      "Station: E 23 St & 1 Ave → Avg Duration: 387.33 sec\n",
      "Station: E 81 St & York Ave → Avg Duration: 385.0 sec\n",
      "Station: W 21 St & 6 Ave → Avg Duration: 382.5 sec\n",
      "Station: E 9 St & Avenue C → Avg Duration: 381.67 sec\n",
      "Station: Grand St & Greene St → Avg Duration: 380.0 sec\n",
      "Station: St Marks Pl & 2 Ave → Avg Duration: 378.75 sec\n",
      "Station: E 37 St & Lexington Ave → Avg Duration: 378.0 sec\n",
      "Station: Myrtle Ave & Lewis Ave → Avg Duration: 377.0 sec\n",
      "Station: 1 Ave & E 18 St → Avg Duration: 374.0 sec\n",
      "Station: E 11 St & 1 Ave → Avg Duration: 373.0 sec\n",
      "Station: 1 Ave & E 44 St → Avg Duration: 372.0 sec\n",
      "Station: Broadway & W 32 St → Avg Duration: 368.0 sec\n",
      "Station: Kent Ave & S 11 St → Avg Duration: 365.0 sec\n",
      "Station: Broadway & W 24 St → Avg Duration: 362.0 sec\n",
      "Station: 9 Ave & W 16 St → Avg Duration: 359.5 sec\n",
      "Station: Riverside Dr & W 82 St → Avg Duration: 358.0 sec\n",
      "Station: Lafayette St & E 8 St → Avg Duration: 356.5 sec\n",
      "Station: W 13 St & 5 Ave → Avg Duration: 343.5 sec\n",
      "Station: Henry St & Grand St → Avg Duration: 336.0 sec\n",
      "Station: Pike St & Monroe St → Avg Duration: 331.0 sec\n",
      "Station: Division St & Bowery → Avg Duration: 325.0 sec\n",
      "Station: Berry St & N 8 St → Avg Duration: 325.0 sec\n",
      "Station: Franklin Ave & Myrtle Ave → Avg Duration: 322.0 sec\n",
      "Station: Clinton Ave & Myrtle Ave → Avg Duration: 314.5 sec\n",
      "Station: McGuinness Blvd & Eagle St → Avg Duration: 307.0 sec\n",
      "Station: 8 Ave & W 31 St → Avg Duration: 302.0 sec\n",
      "Station: E 7 St & Avenue A → Avg Duration: 298.0 sec\n",
      "Station: E 16 St & 5 Ave → Avg Duration: 293.0 sec\n",
      "Station: Clark St & Henry St → Avg Duration: 292.0 sec\n",
      "Station: E 48 St & 3 Ave → Avg Duration: 286.0 sec\n",
      "Station: Forsyth St & Broome St → Avg Duration: 284.0 sec\n",
      "Station: LaGuardia Pl & W 3 St → Avg Duration: 280.0 sec\n",
      "Station: W 13 St & Hudson St → Avg Duration: 280.0 sec\n",
      "Station: E 6 St & Avenue B → Avg Duration: 277.67 sec\n",
      "Station: Lexington Ave & E 29 St → Avg Duration: 275.0 sec\n",
      "Station: E 3 St & 1 Ave → Avg Duration: 269.0 sec\n",
      "Station: W 27 St & 7 Ave → Avg Duration: 266.0 sec\n",
      "Station: Hicks St & Montague St → Avg Duration: 261.0 sec\n",
      "Station: Jay St & Tech Pl → Avg Duration: 254.0 sec\n",
      "Station: E 10 St & 5 Ave → Avg Duration: 251.0 sec\n",
      "Station: DeKalb Ave & Vanderbilt Ave → Avg Duration: 248.0 sec\n",
      "Station: St James Pl & Pearl St → Avg Duration: 240.5 sec\n",
      "Station: E 32 St & Park Ave → Avg Duration: 235.0 sec\n",
      "Station: Broadway & Roebling St → Avg Duration: 233.0 sec\n",
      "Station: Broadway & E 14 St → Avg Duration: 228.0 sec\n",
      "Station: St James Pl & Oliver St → Avg Duration: 224.0 sec\n",
      "Station: Driggs Ave & Lorimer St → Avg Duration: 223.0 sec\n",
      "Station: 10 Ave & W 28 St → Avg Duration: 223.0 sec\n",
      "Station: Canal St & Rutgers St → Avg Duration: 213.0 sec\n",
      "Station: E 30 St & Park Ave S → Avg Duration: 212.0 sec\n",
      "Station: W 4 St & 7 Ave S → Avg Duration: 205.0 sec\n",
      "Station: Maiden Ln & Pearl St → Avg Duration: 204.0 sec\n",
      "Station: Broadway & Whipple St → Avg Duration: 192.0 sec\n",
      "Station: W 13 St & 7 Ave → Avg Duration: 189.0 sec\n",
      "Station: E 11 St & Broadway → Avg Duration: 181.0 sec\n",
      "Station: W 20 St & 8 Ave → Avg Duration: 164.0 sec\n",
      "Station: Milton St & Franklin St → Avg Duration: 143.0 sec\n",
      "Station: Liberty St & Broadway → Avg Duration: 129.0 sec\n",
      "Station: Bank St & Washington St → Avg Duration: 127.0 sec\n",
      "Station: Catherine St & Monroe St → Avg Duration: 101.0 sec\n",
      "Station: Howard St & Centre St → Avg Duration: 91.0 sec\n",
      "Station: John St & William St → Avg Duration: 73.0 sec\n"
     ]
    }
   ],
   "source": [
    "#Filter: start_time hour must be ≥ 7 and < 9\n",
    "#Group by: start_station_name\n",
    "#Calculate average: use $avg on tripduration\n",
    "\n",
    "def average_trip_duration_by_station_morning(collection):\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"$expr\": {\n",
    "                    \"$and\": [\n",
    "                        {\"$gte\": [{\"$hour\": \"$start_time\"}, 7]},   # Hour >= 7\n",
    "                        {\"$lt\":  [{\"$hour\": \"$start_time\"}, 9]}    # Hour < 9\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$group\": {\n",
    "                \"_id\": \"$start_station_name\",              # Group by start station\n",
    "                \"average_duration\": {\"$avg\": \"$tripduration\"}  # Calculate average trip duration\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sort\": {\"average_duration\": -1}  # (Optional) Sort by longest average trips first\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return list(collection.aggregate(pipeline))\n",
    "\n",
    "results = average_trip_duration_by_station_morning(collection)\n",
    "\n",
    "for station in results:\n",
    "    print(f\"Station: {station['_id']} → Avg Duration: {round(station['average_duration'], 2)} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc412f4",
   "metadata": {},
   "source": [
    "* Quel est le top 3 des stations avec la plus forte fréquentation de prise de location, entre 6h et 8h ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f117b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "189a1e88",
   "metadata": {},
   "source": [
    "* Quelle est la durée médiane des trajets pour les + de 65 ans ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979700e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4877aa1c",
   "metadata": {},
   "source": [
    "* Quelle est la répartition des trajets (nombre de trajets) par tranche horaire de 2 heures (faire visualisation, 0h-2h, 2h-4h etc..) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ed3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ac09775",
   "metadata": {},
   "source": [
    "* Quel est le temps moyen passé en trajet pour chaque genre, filtré sur les trajets de plus de 10 minutes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b73a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6b00bf",
   "metadata": {},
   "source": [
    "* Combien de trajets ont démarré pour chaque station pendant les heures de pointe (ex. 7h-9h et 17h-19h) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71418a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36a1b288",
   "metadata": {},
   "source": [
    "* Quel est l'âge le plus courant pour les locations de 18h à 20h ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14da1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
